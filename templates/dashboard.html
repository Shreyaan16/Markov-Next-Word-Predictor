<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ title }}</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.6; padding: 20px; max-width: 1200px; margin: auto; background-color: #f9f9f9; }
        nav { background-color: #fff; border-radius: 8px; padding: 10px 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 20px; }
        nav a { font-weight: 600; text-decoration: none; color: #007aff; padding: 8px 12px; }
        nav a.active { background-color: #eef5ff; border-radius: 6px; }
        .container { background-color: #fff; border-radius: 8px; padding: 30px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 20px; }
        h1 { color: #333; }
        h2 { border-bottom: 2px solid #007aff; padding-bottom: 5px; color: #007aff; margin-top: 40px; }
        h3 { color: #555; }
        pre { background-color: #2d2d2d; color: #f1f1f1; padding: 15px; border-radius: 6px; overflow-x: auto; font-family: "SF Mono", "Consolas", monospace; font-size: 14px; }
        .graph-container { text-align: center; margin-top: 20px; }
        .graph-container img { max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); }
        .grid-container { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        @media (max-width: 900px) {
            .grid-container { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <nav>
        <a href="/">üöÄ Predictor App</a>
        <a href="/dashboard" class="active">üìä Analysis Dashboard</a>
    </nav>

    <div class="container">
        <h1>Stochastic Model Analysis (Order-{{ model_order }})</h1>
        <p>This dashboard demonstrates the core mathematical concepts from the lecture slides, using the trained text model.</p>

        <h2>1. n-Step Transition Probability (P‚Åø)</h2>
        <p>
            This calculation answers a question like "What is the probability of moving from state 'i' to state 'j' in exactly 'n' steps?". 
            This is analogous to the "Harvard Grandson" problem in slides, which calculates an entry in the <b>P¬≤</b> matrix.
        </p>
        <pre>{{ n_step_res }}</pre>

        <h2>2. Chapman-Kolmogorov Equation</h2>
        <p>
             This theorem validates the Markov property, stating that <b>P<sup>(n+m)</sup> = P<sup>n</sup> √ó P<sup>m</sup></b>.
            We test this by calculating both sides of the equation for a sample transition.
        </p>
        <pre>{{ ck_res }}</pre>

        <h2>3. State Classification & Class Structure</h2>
        <p>
             The state space is partitioned into <b>Communicating Classes</b>. A class is <b>Recurrent</b> if it has no exits (a "trap") 
            and <b>Transient</b> if it has an exit. Our model's "language engine" is the largest recurrent class.
        </p>
        <pre>{{ class_res }}</pre>

        <h2>4. Ergodicity: Periodicity & Recurrence</h2>
        <p>
             An <b>Ergodic</b> chain (Irreducible, Positive Recurrent, Aperiodic) guarantees a unique stationary distribution.
        </p>
        
        <h3>Periodicity</h3>
        <p>
             The period is the GCD of all possible return path lengths. A period of 1 means the state is <b>Aperiodic</b>.
        </p>
        <pre>Period of {{ start_state_str }}: {{ period_res }}</pre>
        
        <h3>Positive Recurrence</h3>
        <p>
             A state is <b>Positive Recurrent</b> if its expected return time is finite. For a finite chain, all recurrent states are positive recurrent.
            The expected return time is <b>1 / œÄ<sub>i</sub></b>.
        </p>
        <pre>Expected Return Time for {{ start_state_str }}: {{ recur_res }}</pre>
        
        <h3>Conclusion: This chain is Ergodic.</h3>


        <h2>5. Stationary & Limiting Distribution (œÄ)</h2>
        <p>
             Because the chain is Ergodic, a unique <b>Stationary Distribution (œÄ)</b> exists, which solves <b>œÄ = œÄP</b>. 
            This distribution, <b>œÄ<sub>j</sub></b>, represents the long-run proportion of time the chain spends in state <b>j</b>.
        </p>
        <h3>Top 10 States in Stationary Distribution:</h3>
        <pre>{{ stationary_res }}</pre>
        <div class="graph-container">
            <img src="/static/images/stationary_dist.png" alt="Stationary Distribution Graph">
        </div>
        
        <h3>Limiting Distribution</h3>
        <p>
             The Ergodic theorem also states that the <b>Limiting Distribution</b> exists and is equal to <b>œÄ</b>.
            This means <b>lim<sub>n‚Üí‚àû</sub> P<sub>ij</sub><sup>n</sup> = œÄ<sub>j</sub></b> for all starting states <i>i</i>.
            The graph below simulates this (like the weather example), showing the probability of visiting a state converging over time.
        </p>
        <div class="graph-container">
            <img src="/static/images/convergence.png" alt="Convergence Graph">
        </div>

        <h2>6. Visual Analysis of the Chain</h2>
        <p>These graphs provide a high-level overview of the trained model's properties, based on the concepts from the slides.</p>
        <div class="grid-container">
            <div class="graph-container">
                <h3>Transition Matrix (Top 20 States)</h3>
                <p>A heatmap of the <b>P</b> matrix for the most common states.</p>
                <img src="/static/images/transition_matrix.png" alt="Transition Matrix Heatmap">
            </div>
            
        </div>
    </div>
</body>
</html>